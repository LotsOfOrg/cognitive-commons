"""Core functionality for data ingestion, hashing, and quality checking."""

# AUTOGENERATED! DO NOT EDIT! File to edit: ../nbs/00_data.ipynb.

# %% auto 0
__all__ = ['DataQualityChecker', 'ContentProvenance', 'ContentStore']

# %% ../nbs/00_data.ipynb 1
from fastcore.basics import *
from fastcore.test import *
import hashlib
from pathlib import Path
from typing import Dict, List, Optional, Tuple
import json
import numpy as np
from datetime import datetime,timezone


# %% ../nbs/00_data.ipynb 4
class DataQualityChecker:
    """Quality checking pipeline inspired by FineWeb's approach"""
    def __init__(self, min_quality_score: float = 0.12):
        self.min_quality_score = min_quality_score
    
    def check_basic_quality(self, content: str) -> Dict[str, float]:
        """Basic quality checks similar to FineWeb's base filtering"""
        scores = {}
        
        # Check fraction of lines ending with punctuation
        lines = content.split('\n')
        punct_lines = sum(1 for l in lines if l.strip() and l.strip()[-1] in '.!?')
        scores['punctuation_ratio'] = punct_lines / len(lines) if lines else 0
        
        # Check for duplicate lines (similar to FineWeb's line deduplication)
        unique_lines = set(lines)
        scores['unique_lines_ratio'] = len(unique_lines) / len(lines) if lines else 0
        
        # Check for short lines (FineWeb removes docs with too many short lines)
        short_lines = sum(1 for l in lines if len(l.strip()) < 30)
        scores['short_lines_ratio'] = short_lines / len(lines) if lines else 1
        
        return scores
    
    def calculate_quality_score(self, content: str) -> float:
        """Calculate overall quality score"""
        scores = self.check_basic_quality(content)
        
        # Weights could be tuned based on empirical results
        quality_score = (
            0.4 * scores['punctuation_ratio'] +
            0.4 * scores['unique_lines_ratio'] +
            0.2 * (1 - scores['short_lines_ratio'])
        )
        
        return quality_score
    
    def is_acceptable(self, content: str) -> Tuple[bool, Dict[str, float]]:
        """Check if content meets minimum quality standards"""
        scores = self.check_basic_quality(content)
        quality_score = self.calculate_quality_score(content)
        return quality_score >= self.min_quality_score, {
            'quality_score': quality_score,
            **scores
        }


# %% ../nbs/00_data.ipynb 6
class ContentProvenance:
    """Tracks content reuse and impact across training runs"""
    def __init__(self):
        self.citation_graph = {}  # content_id -> list of derived_content_ids
        self.usage_history = {}   # content_id -> list of model_version_ids
        self.quality_history = {} # content_id -> list of quality scores
        
    def record_usage(self, content_id: str, model_version: str, 
                    quality_impact: float):
        """Record when content is used in training"""
        if content_id not in self.usage_history:
            self.usage_history[content_id] = []
        if content_id not in self.quality_history:
            self.quality_history[content_id] = []
            
        self.usage_history[content_id].append(model_version)
        self.quality_history[content_id].append(quality_impact)
    
    def calculate_impact_score(self, content_id: str) -> float:
        """Calculate content impact based on usage and quality history"""
        if content_id not in self.quality_history:
            return 0.0
            
        # Average quality impact weighted by recency
        weights = np.exp(np.arange(len(self.quality_history[content_id])))
        weighted_avg = np.average(
            self.quality_history[content_id], 
            weights=weights
        )
        
        # Boost score based on number of uses
        usage_multiplier = 1 + np.log1p(len(self.usage_history[content_id]))
        
        return weighted_avg * usage_multiplier


# %% ../nbs/00_data.ipynb 8
class ContentStore:
    """Manages storage and retrieval of training data content with quality checking and provenance tracking"""
    def __init__(self, store_path: Path, min_quality_score: float = 0.12):
        self.store_path = Path(store_path)
        self.store_path.mkdir(exist_ok=True)
        self.index_file = self.store_path/'index.json'
        self.quality_checker = DataQualityChecker(min_quality_score=min_quality_score)
        self.provenance = ContentProvenance()
        self._load_index()
    
    def _load_index(self):
        """Load or initialize the content index"""
        if self.index_file.exists():
            self.index = json.loads(self.index_file.read_text())
        else:
            self.index = {}
            self._save_index()
    
    def _save_index(self):
        """Save the current index to disk"""
        self.index_file.write_text(json.dumps(self.index, indent=2))
    
    def add_content(self, content: str, contributor_id: str) -> Tuple[Optional[str], Dict[str, float]]:
        """
        Add new content to the store if it passes quality checks
        Returns: (content_id, quality_scores) or (None, quality_scores) if rejected
        """
        # Check quality first
        is_acceptable, quality_scores = self.quality_checker.is_acceptable(content)
        if not is_acceptable:
            return None, quality_scores
        
        content_id = hashlib.sha256(content.encode()).hexdigest()
        if content_id in self.index:
            return content_id, quality_scores
        
        timestamp = datetime.now(timezone.utc).isoformat()
        self.index[content_id] = {
            'contributor_id': contributor_id,
            'timestamp': timestamp,
            'size': len(content),
            'quality_scores': quality_scores
        }
        
        (self.store_path/content_id).write_text(content)
        self._save_index()
        return content_id, quality_scores
    
    def record_usage(self, content_id: str, model_version: str, quality_impact: float):
        """Record content usage in model training"""
        if content_id not in self.index:
            raise ValueError(f"Content ID {content_id} not found")
        
        self.provenance.record_usage(content_id, model_version, quality_impact)
        
        # Update index with latest impact score
        self.index[content_id]['impact_score'] = self.provenance.calculate_impact_score(content_id)
        self._save_index()
    
    def get_content(self, content_id: str) -> Optional[str]:
        """Retrieve content by ID"""
        if content_id not in self.index:
            return None
        return (self.store_path/content_id).read_text()
    
    def get_metadata(self, content_id: str) -> Optional[Dict]:
        """Get all metadata for a content item"""
        return self.index.get(content_id)

